apiVersion: batch/v1
kind: Job
metadata:
  name: inference-job-a  # This is a template
spec:
  template:
    spec:
      containers:
      - name: ml-container
        image: us-central1-docker.pkg.dev/jetrr-cloud/training-app/training-main-dev:2.0
        command: ["bash", "-c", "mkdir -p model output && gsutil -m cp -r gs://envison-us-central1-dev/5893016f-2e65-470c-9835-492d038e5a18/model . && gsutil cp gs://configs-us-central1/prompts/prompts-v4.json prompt.json && python3 infer-dreambooth.py --model_path='/root/model' --save_path='/root/output' --prompt_file='/root/prompt.json' --gender='male' && gsutil -m cp -r output gs://envison-us-central1-dev/aa-test/output"]
        args: []  # Placeholder for arguments
        resources:
          limits:
            nvidia.com/gpu: 1
      nodeSelector:
        # node.kubernetes.io/instance-type: n1-standard-4
        cloud.google.com/gke-accelerator: nvidia-tesla-t4
      restartPolicy: Never
  backoffLimit: 0
